#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method : CFMlpANN
Creator: perieanu
Date   : Fri Sep 28 17:13:03 2007
Host   : Linux lxbuild022.cern.ch 2.4.21-47.0.1.EL.cernsmp #1 SMP Thu Oct 19 16:35:52 CEST 2006 i686 i686 i386 GNU/Linux
Dir    : /work/perieanu/tracking_Brunel_v31r7/Brunel_v31r7/TrNN/version_040se/TMVA_B
Training events: 20000


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: False [verbose flag]
H: True [help flag]
NCycles: 5000 [Number of training cycles]
HiddenLayers: "N,N" [Specification of the hidden layers]
# Default:
D: False [use-decorrelated-variables flag (for backward compatibility)]
Preprocess: "None" [Variable Decorrelation Method]
PreprocessType: "Signal" [Use signal or background for Preprocess]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 8
                           eta                           eta    'F'    [1.5778,6.58105]
                      chi2Prob                      chi2Prob    'F'    [0,0.999823]
                           ndf                           ndf    'F'    [8,50]
                        TThits                        TThits    'F'    [0,8]
                      VeLohits                      VeLohits    'F'    [4,28]
                          Dvar                          Dvar    'F'    [-45.6392,51.4178]
                        NComOT                        NComOT    'F'    [1,8]
                           var                           var    'F'    [0.0855892,51.4178]


#WGT -*-*-*-*-*-*-*-*-*-*-*-*- weights -*-*-*-*-*-*-*-*-*-*-*-*-

8    2
1   -1
1   -1
1   -1
1   -1
1   -1
1   -1
1   -1
1   -1
4
8     8     8     2     
-0.767851   -2.33426   1.21036   2.8972   -0.847006   0.0118499   -4.47431   3.73188   
0.371919   -0.348043   0.875145   0.950509   -0.523853   2.49596   1.83717   0.195243   
-0.372116   -0.941694   0.338163   -0.276775   0.386627   -0.153916   0.243166   6.52214   
-0.743813   -0.593152   0.999348   -0.737091   0.714777   0.135734   -0.0733387   1.21214   
0.394424   -0.238063   0.639613   -0.603386   -0.117325   -3.31762   -0.537812   -0.963418   
-0.631028   1.22062   0.225158   0.432851   0.406121   -0.0387088   -0.167591   -1.06506   
-0.222456   1.17506   -0.245706   -2.4817   0.973217   -0.887727   -1.02546   1.65543   
-0.63615   -1.82243   1.19435   3.06136   -0.965702   0.0992273   0.80208   -1.93188   
0.128367   -0.607216   0.236374   -0.280119   -0.0740562   1.37153   -4.7322   -1.74914   


1.66858   0.565999   -1.56788   0.882126   -0.120647   0.283026   0.470934   0.394285   
-0.0810737   -0.847093   0.138042   -1.02307   0.430991   -0.220934   -0.593494   -0.594645   
-2.30346   -0.599008   2.01496   0.828058   -0.114292   0.402685   0.459591   0.439415   
1.43088   0.72737   -1.11502   -0.613876   0.0625069   0.134101   0.0570826   0.0403713   
3.34318   1.74811   -2.84189   -0.0226761   -0.139698   0.161885   0.273995   0.410108   
-1.14617   -0.588596   1.18544   0.422671   -0.113658   0.292766   0.36683   0.17839   
0.61151   -2.70594   -0.720239   -1.67237   0.254907   -0.0126614   -0.323914   -0.491073   
-3.71773   1.69841   3.6699   0.442662   -0.00527613   -0.143918   -0.0758445   -0.0392774   
-2.74013   1.22242   2.67988   0.661406   -0.214376   0.278476   0.37688   0.556707   


0.985024   -0.963896   
-3.04162   3.06427   
2.00557   -1.98464   
2.83781   -2.82304   
1.98211   -1.93106   
-0.44809   0.320114   
0.571979   -0.313762   
0.802131   -0.910593   
0.778642   -1.03348   




1


1


1


1
